{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ling 406 - Term Project - Marco Fonseca (movie reviews)\n",
    "\n",
    "The code below impots the necessary libraries and then saves the positive and negative movie reviews in different variables. This code assumes that the folder \"tex_sentoken\" is in the directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "\n",
    "neg_list = glob.glob(os.path.join(os.getcwd(), \"txt_sentoken/neg\", \"*.txt\"))\n",
    "pos_list = glob.glob(os.path.join(os.getcwd(), \"txt_sentoken/pos\", \"*.txt\"))\n",
    "\n",
    "neg = []\n",
    "pos = []\n",
    "\n",
    "for file_path in neg_list:\n",
    "    with open(file_path) as f_input:\n",
    "        neg.append(f_input.read())\n",
    "\n",
    "\n",
    "for file_path in pos_list:\n",
    "    with open(file_path) as f_input:\n",
    "        pos.append(f_input.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below tokenizes the positive reviews and the negative reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_neg = [nltk.word_tokenize(i) for i in neg]\n",
    "tokens_pos = [nltk.word_tokenize(i) for i in pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code belows adds the word \"neg\" after all of the negative reviews and the word \"pos\" after all of the positive reviews. Then, it creates two variables to be used later. One variable contains all negative and positive reviews, plus its tag as \"pos\" or \"neg\". This variable is then randomized. The determined features will be searched in this tagged variabl. After that, another variable created \"all words\" is created. This variable does not contain the tags and will be used in order to create the features for the trainig data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_neg = []\n",
    "for l in tokens_neg: \n",
    "        tuple = ( l , \"neg\" ) \n",
    "        out_neg.append(tuple)\n",
    "\n",
    "\n",
    "out_pos = []\n",
    "for l in tokens_pos: \n",
    "        tuple = ( l , \"pos\" ) \n",
    "        out_pos.append(tuple)\n",
    "        \n",
    "pos_neg = out_pos + out_neg\n",
    "random.shuffle(pos_neg)\n",
    "\n",
    "all_words = tokens_pos + tokens_neg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a frequency distribution of all words that will be used in order to create the features for the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in all_words for item in sublist]\n",
    "freq_dist = nltk.FreqDist(flat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code belows determines the baseline and the features to be used in this model. The baseline is comprised of unigrams. The second feature is comprised of bigrams. The third feature removes punctiation and preposition, leaving only content words. The last feature contains bigrams and only content words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline = list(freq_dist.keys())\n",
    "bigram_features = list(nltk.bigrams(baseline)) #2nd set of features\n",
    "remove = {\":\", \",\", \".\", \";\", \"?\", \"!\", \"(\", \")\", \"'\",  \"to\", \"a\", \"the\", \"an\", \"on\", \"at\", \"in\"}\n",
    "content_features = [e for e in baseline if e not in remove] #3rd set of features\n",
    "bigrams_content_features =  list(nltk.bigrams(content_features))#4th set of features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates one function to find each one of the features in the document. Since there are three features plus the baseline, 4 functions are created. Varibles containing the output of each of of the features are then created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_features_baseline(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in baseline:\n",
    "        features[w] = (w in words)\n",
    "    return features \n",
    "\n",
    "def find_features_bigrams(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in bigram_features:\n",
    "        features[w] = (w in words)    \n",
    "    return features\n",
    "\n",
    "def find_features_content(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in content_features:\n",
    "        features[w] = (w in words)    \n",
    "    return features\n",
    "\n",
    "def find_features_bigrams_content(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in bigrams_content_features:\n",
    "        features[w] = (w in words)    \n",
    "    return features\n",
    "\n",
    "featuresets_baseline = [(find_features_baseline(rev), category) for (rev, category) in pos_neg]\n",
    "featuresets_bigrams = [(find_features_bigrams(rev), category) for (rev, category) in pos_neg]\n",
    "featuresets_content = [(find_features_content(rev), category) for (rev, category) in pos_neg]\n",
    "featuresets_bigrams_content = [(find_features_bigrams_content(rev), category) for (rev, category) in pos_neg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates the training and test data for the baseline. It was chosen to use 20% of the data for the training data and 80% of it for the test data. It also prints the accuracy for the baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algorithm accuracy of baseline: 0.8054862842892768\n"
     ]
    }
   ],
   "source": [
    "training_set_baseline = featuresets_baseline[:1600]\n",
    "testing_set_baseline = featuresets_baseline[1600:]\n",
    "classifier_baseline = nltk.NaiveBayesClassifier.train(training_set_baseline)\n",
    "print(\"Naive Bayes Algorithm accuracy of baseline:\", (nltk.classify.accuracy(classifier_baseline, testing_set_baseline)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates the training and test data for the bigram feature set. It was chosen to use 20% of the data for the training data and 80% of it for the test data. It also prints the accuracy for this feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algorithm accuracy of bigrams: 0.4688279301745636\n"
     ]
    }
   ],
   "source": [
    "training_set_bigrams = featuresets_bigrams[:1600]\n",
    "testing_set_bigrams = featuresets_bigrams[1600:]\n",
    "classifier_bigrams = nltk.NaiveBayesClassifier.train(training_set_bigrams)\n",
    "print(\"Naive Bayes Algorithm accuracy of bigrams:\", (nltk.classify.accuracy(classifier_bigrams, testing_set_bigrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates the training and test data for the content words feature set. It was chosen to use 20% of the data for the training data and 80% of it for the test data. It also prints the accuracy for this feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algorithm accuracy of content words: 0.8029925187032418\n"
     ]
    }
   ],
   "source": [
    "training_set_content = featuresets_content[:1600]\n",
    "testing_set_content = featuresets_content[1600:]\n",
    "classifier_content = nltk.NaiveBayesClassifier.train(training_set_content)\n",
    "print(\"Naive Bayes Algorithm accuracy of content words:\", (nltk.classify.accuracy(classifier_content, testing_set_content)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates the training and test data for the bigram feature set only with content words. It was chosen to use 20% of the data for the training data and 80% of it for the test data. It also prints the accuracy for this feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algorithm accuracy of bigrams (only content words) 0.4688279301745636\n"
     ]
    }
   ],
   "source": [
    "training_set_bigrams_content = featuresets_bigrams_content[:1600]\n",
    "testing_set_bigrams_content = featuresets_bigrams_content[1600:]\n",
    "classifier_bigrams_content = nltk.NaiveBayesClassifier.train(training_set_bigrams_content)\n",
    "print(\"Naive Bayes Algorithm accuracy of bigrams (only content words)\", (nltk.classify.accuracy(classifier_bigrams_content, testing_set_bigrams_content)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
